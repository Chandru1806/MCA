{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f8b8d9-b3c9-4414-9b41-bf50c2dc94f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Found STD files: ['3e7a0a30_Acct_Statement_XX5782_17082025__STD_HDFC.csv', 'abaa7fd0_AST1755014126988__STD_KOTAK.csv', 'ac929ae0_cub_bank_statememnt__STD_CUB.csv']\n",
      "\n",
      "[‚úÖ] Reading file: 3e7a0a30_Acct_Statement_XX5782_17082025__STD_HDFC.csv\n",
      "[üîç] Columns: ['Transaction_ID', 'Transaction_Date', 'Description', 'Debit_Amount', 'Credit_Amount', 'Balance', 'Bank_Name']\n",
      "\n",
      "[‚úÖ] Reading file: abaa7fd0_AST1755014126988__STD_KOTAK.csv\n",
      "[üîç] Columns: ['Transaction_ID', 'Transaction_Date', 'Description', 'Debit_Amount', 'Credit_Amount', 'Balance', 'Bank_Name']\n",
      "\n",
      "[‚úÖ] Reading file: ac929ae0_cub_bank_statememnt__STD_CUB.csv\n",
      "[üîç] Columns: ['Transaction_ID', 'Transaction_Date', 'Description', 'Debit_Amount', 'Credit_Amount', 'Balance', 'Bank_Name']\n",
      "‚úÖ Combined dataset saved as: transactions_dataset.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction_Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Debit_Amount</th>\n",
       "      <th>Credit_Amount</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Bank_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>UPI-ZOMATO 0000503337661345 LTD-ZOMATO-ORDER@P...</td>\n",
       "      <td>306.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101506.06</td>\n",
       "      <td>HDFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>UPI-MURUGADOSS 0000503330329806 M-9444387308@O...</td>\n",
       "      <td>300.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101206.06</td>\n",
       "      <td>HDFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>UPI-RAZORPAYREDBUS-REDBUS-PAYMENT@ICICI- 00005...</td>\n",
       "      <td>1715.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99490.11</td>\n",
       "      <td>HDFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>UPI-MEENAKSHI 0000503335966668 S-MEENAKSHISANK...</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89490.11</td>\n",
       "      <td>HDFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-02</td>\n",
       "      <td>UPI-RIZWAN-GPAYRIZWAN546@OKICICI-KKBK000 00005...</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89414.11</td>\n",
       "      <td>HDFC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction_Date                                        Description  \\\n",
       "0       2025-02-02  UPI-ZOMATO 0000503337661345 LTD-ZOMATO-ORDER@P...   \n",
       "1       2025-02-02  UPI-MURUGADOSS 0000503330329806 M-9444387308@O...   \n",
       "2       2025-02-02  UPI-RAZORPAYREDBUS-REDBUS-PAYMENT@ICICI- 00005...   \n",
       "3       2025-02-02  UPI-MEENAKSHI 0000503335966668 S-MEENAKSHISANK...   \n",
       "4       2025-03-02  UPI-RIZWAN-GPAYRIZWAN546@OKICICI-KKBK000 00005...   \n",
       "\n",
       "   Debit_Amount  Credit_Amount    Balance Bank_Name  \n",
       "0        306.25            0.0  101506.06      HDFC  \n",
       "1        300.00            0.0  101206.06      HDFC  \n",
       "2       1715.95            0.0   99490.11      HDFC  \n",
       "3      10000.00            0.0   89490.11      HDFC  \n",
       "4         76.00            0.0   89414.11      HDFC  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Use current directory\n",
    "data_dir = Path(\".\")\n",
    "\n",
    "# Look for all STD CSVs\n",
    "std_files = list(data_dir.glob(\"*__STD_*.csv\"))\n",
    "\n",
    "# Debug: list all matched files\n",
    "print(\"Found STD files:\", [f.name for f in std_files])\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for file in std_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        print(f\"\\n[OK] Reading file: {file.name}\")\n",
    "        print(f\"[INFO] Columns: {df.columns.tolist()}\")\n",
    "\n",
    "        bank_name = file.stem.split(\"__STD_\")[-1]\n",
    "        df[\"Bank_Name\"] = bank_name\n",
    "\n",
    "        standard_columns = [\n",
    "            \"Transaction_Date\", \"Description\", \"Debit_Amount\",\n",
    "            \"Credit_Amount\", \"Balance\", \"Bank_Name\"\n",
    "        ]\n",
    "\n",
    "        # Add missing columns\n",
    "        for col in standard_columns:\n",
    "            if col not in df.columns:\n",
    "                print(f\"[WARNING] Missing column: {col} -> Adding blank column\")\n",
    "                df[col] = \"\"\n",
    "\n",
    "        # Reorder\n",
    "        df = df[standard_columns]\n",
    "\n",
    "        # Normalize values\n",
    "        for amt_col in [\"Debit_Amount\", \"Credit_Amount\", \"Balance\"]:\n",
    "            df[amt_col] = pd.to_numeric(df[amt_col], errors='coerce').fillna(0.0)\n",
    "\n",
    "        # Convert date\n",
    "        df[\"Transaction_Date\"] = pd.to_datetime(df[\"Transaction_Date\"], errors='coerce')\n",
    "        df[\"Transaction_Date\"] = df[\"Transaction_Date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {file.name}: {e}\")\n",
    "\n",
    "# Final CSV Output\n",
    "if all_dfs:\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    final_df.to_csv(\"transactions_dataset.csv\", index=False)\n",
    "    print(\"Combined dataset saved as: transactions_dataset.csv\")\n",
    "    display(final_df.head())\n",
    "else:\n",
    "    print(\"WARNING: No valid dataframes to combine.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f27f16ce-acde-4592-a1ac-85f5a4c9ce05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not detect bank from 3e7a0a30_Acct_Statement_XX5782_17082025__REJECTS_HDFC (1).csv\n",
      "\n",
      "Processing: 3e7a0a30_Acct_Statement_XX5782_17082025__REJECTS_HDFC.csv (HDFC)\n",
      "Saved: 3e7a0a30_Acct_Statement_XX5782_17082025__RECOVERED_HDFC.csv\n",
      "\n",
      "Processing: abaa7fd0_AST1755014126988__REJECTS_KOTAK.csv (KOTAK)\n",
      "ERROR: Error in abaa7fd0_AST1755014126988__REJECTS_KOTAK.csv: No columns to parse from file\n",
      "\n",
      "Processing: ac929ae0_cub_bank_statememnt__REJECTS_CUB.csv (CUB)\n",
      "ERROR: Error in ac929ae0_cub_bank_statememnt__REJECTS_CUB.csv: No columns to parse from file\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- UTILITIES ----------\n",
    "def to_float(value):\n",
    "    try:\n",
    "        return float(str(value).replace(\",\", \"\").strip())\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def is_float(val):\n",
    "    try:\n",
    "        float(str(val).replace(\",\", \"\").strip())\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def standardize_date(date_str):\n",
    "    for fmt in (\"%d/%m/%y\", \"%d-%m-%Y\", \"%d-%b-%Y\"):\n",
    "        try:\n",
    "            return datetime.strptime(date_str.strip(), fmt).strftime(\"%Y-%m-%d\")\n",
    "        except:\n",
    "            continue\n",
    "    return \"\"\n",
    "\n",
    "# ---------- BANK-SPECIFIC CLEANING ----------\n",
    "def clean_reject_rows(df, bank):\n",
    "    cleaned_rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        values = row.dropna().values\n",
    "        if len(values) < 4:\n",
    "            continue  # skip empty\n",
    "\n",
    "        try:\n",
    "            date = standardize_date(values[0])\n",
    "            desc = values[1]\n",
    "\n",
    "            debit, credit, balance = 0.0, 0.0, 0.0\n",
    "\n",
    "            if bank == \"HDFC\":\n",
    "                if len(values) >= 6:\n",
    "                    debit = to_float(values[4])\n",
    "                    credit = to_float(values[5])\n",
    "                    balance = to_float(values[6]) if len(values) > 6 else 0.0\n",
    "            elif bank == \"KOTAK\":\n",
    "                # Kotak: values[4] contains \"(Dr)\" or \"(Cr)\"\n",
    "                amount_field = str(values[4])\n",
    "                if \"(Dr)\" in amount_field:\n",
    "                    debit = to_float(amount_field.replace(\"(Dr)\", \"\"))\n",
    "                elif \"(Cr)\" in amount_field:\n",
    "                    credit = to_float(amount_field.replace(\"(Cr)\", \"\"))\n",
    "                balance = to_float(values[5]) if len(values) > 5 else 0.0\n",
    "            elif bank == \"CUB\":\n",
    "                # Try guessing based on field length\n",
    "                for val in values:\n",
    "                    if is_float(val):\n",
    "                        if debit == 0.0:\n",
    "                            debit = to_float(val)\n",
    "                        elif credit == 0.0:\n",
    "                            credit = to_float(val)\n",
    "                        else:\n",
    "                            balance = to_float(val)\n",
    "\n",
    "            cleaned_rows.append({\n",
    "                \"Transaction_Date\": date,\n",
    "                \"Description\": str(desc).strip(),\n",
    "                \"Debit_Amount\": debit,\n",
    "                \"Credit_Amount\": credit,\n",
    "                \"Balance\": balance,\n",
    "                \"Bank_Name\": bank.upper()\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Skipped row {i}: {e}\")\n",
    "\n",
    "    return cleaned_rows\n",
    "\n",
    "# ---------- MAIN WORKFLOW ----------\n",
    "def clean_all_reject_files():\n",
    "    reject_files = list(Path(\".\").glob(\"*__REJECTS_*.csv\"))\n",
    "    if not reject_files:\n",
    "        print(\"ERROR: No reject files found.\")\n",
    "        return\n",
    "\n",
    "    for file in reject_files:\n",
    "        bank = re.search(r\"__REJECTS_(\\w+)\\.csv\", file.name)\n",
    "        if not bank:\n",
    "            print(f\"ERROR: Could not detect bank from {file.name}\")\n",
    "            continue\n",
    "\n",
    "        bank_name = bank.group(1).upper()\n",
    "        print(f\"\\nProcessing: {file.name} ({bank_name})\")\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            cleaned = clean_reject_rows(df, bank_name)\n",
    "\n",
    "            if cleaned:\n",
    "                result_df = pd.DataFrame(cleaned)\n",
    "                result_df.insert(0, \"Transaction_ID\", [f\"{bank_name[:3]}_{i+1:05d}\" for i in range(len(result_df))])\n",
    "                output_file = file.name.replace(\"__REJECTS_\", \"__RECOVERED_\")\n",
    "                result_df.to_csv(output_file, index=False)\n",
    "                print(f\"Saved: {output_file}\")\n",
    "            else:\n",
    "                print(\"WARNING: No valid rows recovered.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Error in {file.name}: {e}\")\n",
    "\n",
    "# ---------- RUN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    clean_all_reject_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "691a30ec-3073-4d32-be31-809d3842b878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged recovered HDFC data into transactions_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "\n",
    "# Paths\n",
    "final_csv_path = Path(\"transactions_dataset.csv\")\n",
    "recovered_hdfc_path = Path(\"3e7a0a30_Acct_Statement_XX5782_17082025__RECOVERED_HDFC.csv\")\n",
    "\n",
    "# Load both datasets\n",
    "final_df = pd.read_csv(final_csv_path)\n",
    "recovered_df = pd.read_csv(recovered_hdfc_path)\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_cols = ['Transaction_Date', 'Description', 'Debit_Amount', 'Credit_Amount', 'Balance', 'Bank_Name']\n",
    "\n",
    "missing_cols = [col for col in required_cols if col not in recovered_df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"WARNING: Missing columns in recovered HDFC: {missing_cols}\")\n",
    "    for col in missing_cols:\n",
    "        recovered_df[col] = \"\"  # Fill missing columns with empty\n",
    "\n",
    "# Assign Transaction_ID if not present\n",
    "if \"Transaction_ID\" not in recovered_df.columns:\n",
    "    recovered_df.insert(0, \"Transaction_ID\", [str(uuid.uuid4())[:8] for _ in range(len(recovered_df))])\n",
    "\n",
    "# Align column order to match final_df\n",
    "recovered_df = recovered_df[final_df.columns]\n",
    "\n",
    "# Merge\n",
    "merged_df = pd.concat([final_df, recovered_df], ignore_index=True)\n",
    "\n",
    "# Save\n",
    "merged_df.to_csv(\"transactions_dataset.csv\", index=False)\n",
    "print(\"Merged recovered HDFC data into transactions_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ea60e46-8a00-46f9-9953-b105d18c34ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FIXED file as: 3e7a0a30_Acct_Statement_XX5782_17082025__FIXED_HDFC.csv\n",
      "Final rows: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction_ID</th>\n",
       "      <th>Transaction_Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Debit_Amount</th>\n",
       "      <th>Credit_Amount</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Bank_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDFC_00001</td>\n",
       "      <td></td>\n",
       "      <td>31/07/25</td>\n",
       "      <td>293990.58</td>\n",
       "      <td>43071.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HDFC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction_ID Transaction_Date Description Debit_Amount Credit_Amount  \\\n",
       "0     HDFC_00001                     31/07/25    293990.58      43071.05   \n",
       "\n",
       "  Balance Bank_Name  \n",
       "0     0.0      HDFC  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the recovered file\n",
    "input_file = \"3e7a0a30_Acct_Statement_XX5782_17082025__RECOVERED_HDFC.csv\"\n",
    "output_file = \"3e7a0a30_Acct_Statement_XX5782_17082025__FIXED_HDFC.csv\"\n",
    "\n",
    "# Read the single-row file\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Extract the first row and convert each field to list\n",
    "fields = [\"Transaction_Date\", \"Description\", \"Debit_Amount\", \"Credit_Amount\", \"Balance\"]\n",
    "columns_data = {}\n",
    "\n",
    "for field in fields:\n",
    "    value = df.at[0, field]\n",
    "    lines = str(value).split(\"\\n\") if pd.notna(value) else []\n",
    "    columns_data[field] = lines\n",
    "\n",
    "# Determine max row count\n",
    "max_rows = max(len(v) for v in columns_data.values())\n",
    "\n",
    "# Pad shorter columns\n",
    "for key in columns_data:\n",
    "    while len(columns_data[key]) < max_rows:\n",
    "        columns_data[key].append(\"\")\n",
    "\n",
    "# Build cleaned rows\n",
    "cleaned_rows = []\n",
    "for i in range(max_rows):\n",
    "    cleaned_rows.append({\n",
    "        \"Transaction_ID\": f\"HDFC_{i+1:05d}\",\n",
    "        \"Transaction_Date\": columns_data[\"Transaction_Date\"][i].strip(),\n",
    "        \"Description\": columns_data[\"Description\"][i].strip(),\n",
    "        \"Debit_Amount\": columns_data[\"Debit_Amount\"][i].strip(),\n",
    "        \"Credit_Amount\": columns_data[\"Credit_Amount\"][i].strip(),\n",
    "        \"Balance\": columns_data[\"Balance\"][i].strip(),\n",
    "        \"Bank_Name\": \"HDFC\"\n",
    "    })\n",
    "\n",
    "# Final DataFrame\n",
    "clean_df = pd.DataFrame(cleaned_rows)\n",
    "\n",
    "# Save\n",
    "clean_df.to_csv(output_file, index=False)\n",
    "print(f\"Saved FIXED file as: {output_file}\")\n",
    "print(\"Final rows:\", len(clean_df))\n",
    "display(clean_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8abfa77-0560-4aba-8859-ce95c467723a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
